2018/10/04　Deep Learning基礎講座
(6dmki1r)

・Stack overflow CEO(Joel Spolsky)

脳＝電気信号＋化学変化⇒情報処理＝プログラムで実現できないはずがない
　ー万能チューリングマシン
それ以外の難しい要素：霊感、（ロジャー・ペンローズ）
　→長い年月でハイパパラメータ

・第1次AIブーム：探索・推論
Artificial Intelligenceが決まる
ゲーム：Minimax法
　モンテカルロ法（途中からランダム）、良い特徴量（駒の位置）
　チェス：10の120乗（1997年）、将棋：10の220乗（2017年）、囲碁：10の360乗（2015年）
　※宇宙の水素原子：10の80乗
★トイプロブレムは解ける＝探索・推論問題として記述できる

・第2次AIブーム：エキスパートシステム（知識を入れると賢くなる）
第5世代コンピュータプロジェクト（1981）：570億円の国家プロジェクト
例）ELIZA（1964）対話システム：ルールシステム→Twitterのボット
★簡単なシステムでも人間は知性を感じた
例）MYCIN
例）Cyc：人が一般的に持っている知識を記述するのは難しい
　→オントロジー：概念・関係（Is a、Part of）：Heavy、Light（ちゃんとかんがえる、効率化）
　　→Watson(2006-)：スコアリング、クイズ番組で勝つ＝見せ方・マーケティング
機械翻訳の難しさ：係り受け
例）フレーム問題（Dennett 1984）
例）シンボルグラウンディング問題（Harnard 1990）
　→シンボルグラウンディング問題：記号システム内のシンボルがどのようにして
　　実世界の意味と結び付けられるか（記号接地問題）（シマウマ＝縞も馬も知ってる）
★知識を書ききれない＋何をどう表現すべきか難しい

・第3次AIブーム：機械学習から表現学習へ
分類（教師あり、教師なし）：どういう変数（特徴量）を使うかが最も大事
★これまでの人工知能の壁≒特徴抽出の壁
　＝人間が現実世界の対象物を観察し「どこに注目」するかを見抜いてモデルの構築を行っていた：最大の問題
　⇒Deep Learningが解決策・突破口（50年来のブレイクスルー）＝DLのその先が凄い
Googleの猫、YoloV2

★深い関数を使った最小二乗法：汎用目的技術（General Purpose Technology）

画像認識＝目の誕生/カンブリア爆発・種の多様化
→労働集約型産業は目を使う：情報産業からリアルな場所で活用（調理、介護、物流、”家事（家電）”）

DL時代のグローバル商社：手でやる仕事が自動化→コストが下がる・最後までコストが残る領域は？
　→王様の生活：料理をさせる、庭の手入れをさせる、パーティの準備をさせる
　＝人間の本能に近い、パーソナライズされた、社会的文脈のなかでの消費行動

・カナディアンマフィア（冬の時代も研究）：若い世代20代後半〜30代前半

・ハードの問題が出てくる（カメラ、ネットワーク）→競争優位
